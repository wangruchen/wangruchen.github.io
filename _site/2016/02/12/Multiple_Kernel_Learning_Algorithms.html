
<!DOCTYPE html>

<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Multiple Kernel Learning Algorithms论文笔记</title>
  <meta name="description" content="">

  <link rel="canonical" href="/2016/02/12/Multiple_Kernel_Learning_Algorithms.html">
  <!-- <link rel="alternate" type="application/rss+xml" title="Wangruchen's Homepage" href="/feed.xml" /> -->

  <!-- Latest compiled and minified CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
 

	
  <!--Added styles css-->	
  <link rel="stylesheet" href="/css/normalize.css"/>

  <link rel="stylesheet" href="/css/custom.css"/>

   <link rel="stylesheet" href="/css/style.css"/>

    <!--Font awesome-->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

   <!--modernizr-->
   <script src="js/modernizr.js"></script>
	


</head>


  <body>
  <!--[if lt IE 7]>
      <strong>It seems your browser is quite a bit old, to get latest browser go to this link <a href="http://browsehappy.com">BROWSE HAPPY </a> And get the happy face</strong>
  <![endif]-->

  
<!-- Start with the header -->
<section class="header" id="header">



    <a class="tab pi-default pi-big pi-flat" target="_blank" href="https://github.com/wangruchen"><i class="fa fa-github"></i> My Github</a>

    <!-- Main Head Title -->
    <h2><a href="/">Wangruchen's Homepage</a></h2>
    <p>-_-</p>




     <a class="page-link" href="">About</a>
</section>


    <div class="container">


        <h1 id="multiple-kernel-learning-algorithms">Multiple Kernel Learning Algorithms论文笔记</h1>

<p>这篇文章第二部分主要讲MKL算法的关键性质，区分不同种算法间的异同。第三部分分类讨论不同MKL算法。第四部分实验。第五部分结论。</p>

<h2 id="section">多核学习六个重要性质</h2>

<p>了解这六个性质可以对MKL算法有一个清楚的分类。这六个性质：</p>

<ol>
  <li>the learning method</li>
  <li>the functional form</li>
  <li>the target function</li>
  <li>the training method</li>
  <li>the base learner</li>
  <li>computation complexity</li>
</ol>

<h3 id="the-learning-method">The Learning Method</h3>

<p>The existing MKL algorithms use different learning methods for determining the kernel combination function. 多核学习算法用不同的学习方法来决定核的结合函数。</p>

<p>主要有5类：</p>

<ol>
  <li>
    <p><strong>Fixed rules</strong>: don’t need any training and parameters. </p>

    <p>按照固定的形式结合核函数，结合函数不需要参数和训练。</p>
  </li>
  <li>
    <p><strong>Heuridtic approaches</strong>: use a parameterized combination function and find the parameters of this function generally by looking at some measure obtained from each kernel function separately.（分别计算出每个核函数对应的参数）</p>

    <p>该方法采用含有参数的结合函数。参数根据每个核函数的表现或核矩阵计算得到。</p>
  </li>
  <li>
    <p><strong>Optimization approaches</strong>: use a parametrized combination function and learn the parameters by solving an optimization problem.（通过解优化问题计算参数）</p>

    <p>该方法采用含有参数的结合函数。参数通过解优化问题得到。</p>

    <p><!--这个优化问题可以是similarity measures或structural risk minimization approaches。--></p>
  </li>
  <li>
    <p><strong>Bayesian approches</strong>: interpret the kernel combination parameters as random variables, put priors on these parameters, and perform inference for learning them and the base learner parameters.</p>
  </li>
  <li>
    <p><strong>Boosting approaches</strong>: inspired from ensemble and boosting methods, iteratively add a new kernel until the performance stops improving.</p>

    <p>灵感来自于集成学习。不断增加新的核知道效果不再提高。</p>
  </li>
</ol>

<h3 id="the-functional-form">The Functional Form</h3>

<p>核结合的函数形式可以分为下面3类：</p>

<ol>
  <li>
    <p><strong>Linear combination method</strong>: </p>

    <p>线性结合方法：基本分为两类：无权重和（unweighted sum）、有权重和（weighted sum）。</p>
  </li>
  <li>
    <p><strong>Nonlinear combination methods</strong>: </p>

    <p>非线性结合方法：用非线性函数，例如乘法、求幂等。</p>
  </li>
  <li>
    <p><strong>Data-dependent combination method</strong>: assign specific kernel weights for each data instance. </p>

    <p>依赖数据的结合方法：为每个数据分配特定的核函数权重。</p>
  </li>
</ol>

<h3 id="the-target-function">The Target Function</h3>

<p>通过优化不同的目标函数（target function）来得到结合函数的参数。目标函数分为三个基本类别：</p>

<ol>
  <li>
    <p><strong>Similarity-based functions</strong>: </p>

    <p>基于相似度的函数：计算合并的核模型和训练集得到的最优核模型之间的相似度量，设置参数使得相似度最大。计算两个核之间相似度的方法有：kernel alignment, Euclidean distance, Kullback-Leibler (KL) divergence, or any other similarity measure。
<!--calculate a similarity metric between the combined kernel matrix and an optimum kernel matrix calculated from the training data and select the combination function parameters that maximize the similarity. --></p>
  </li>
  <li>
    <p><strong>Structural risk functions</strong>: </p>

    <p>结构风险函数：结构风险最小化，最小化正则项之和（对应于降低模型的复杂性和误差）。对核权重的约束可以结合正则项。For example, structural risk function can use the l1-norm, the l2-norm, or a mixed-norm on the kernel weights or feature spaces to pick the model parameters.</p>
  </li>
  <li>
    <p><strong>Bayesian functions</strong>: measure the quality of the resulting kernel function constructed from candidate kernels using a Bayesian formulation.</p>

    <p>贝叶斯函数：通常用likelihood或posterior作为目标函数，找到最大likelihood或最大posterior来确定参数。</p>
  </li>
</ol>

<h3 id="the-training-method">The Training Method</h3>

<p>训练方法：</p>

<ol>
  <li>
    <p><strong>One-step methods</strong>: calculate both the combination function parameters and the parameters of the combined base learner in a single pass.</p>

    <p>不采用迭代，一次计算结合函数的参数和基础分类器参数。先计算出结合函数的参数，然后采用结合的核训练出一个分类器。</p>
  </li>
  <li>
    <p><strong>Two-step methods</strong>: use an iterative approach where each iteration, first we update the combination function parameters while fixing the base learner parameters, and then we update the base learner parameters while fixing the combination function parameters.</p>

    <p>采用迭代的方法，首先更新结合函数的权重参数，然后更每个基础分类器的参数，不断重复上面两步直到收敛。</p>
  </li>
</ol>

<h3 id="the-base-learner">The Base Learner</h3>

<p>目前有很多基于核的学习方法（kernel-based learning algorithm）：</p>

<ul>
  <li>SVM和support vector regression (SVR)</li>
  <li>Kernel Fisher Discriminant analysis (KFD，核函数Fisher鉴别)：先对输入空间的样本进行非线性映射，变换到特征空间，然后在特征空间中利用线性Fisher鉴别寻找易于分类的投影线。</li>
  <li>Regularized kernel discriminant analysis (RKDA)</li>
  <li>kernel ridge regression (KRR，核岭回归) </li>
</ul>

<h3 id="the-computational-complexity">The computational Complexity</h3>

<p>多核学习方法的计算复杂度主要决定于两个方面：训练方法（是one-step还是two-step）和基本分类器的计算复杂程度。</p>

<h2 id="section-1">3</h2>

<h3 id="structural-risk-optimizing-nonlinear-approaches">3.9 Structural Risk Optimizing Nonlinear Approaches</h3>

<p>Ong et al. (2003)提出学习一个核函数来代替核矩阵。在核空间定义一个核函数称为（Hyperkernels）。</p>

<p>Varma and Babu (2009)提出了generalized multiple kernel learning (GMKL)，它的目标函数中包含两个正则化项和一个损失函数。</p>

<!--## 多核学习算法分类讨论

根据多核学习的性质，将现有的多核学习方法分为12类。

### Fixed Rules

在Pavlidis et al. (2001)的文章中，计算每一组数据的核，然后将它们加起来（无权重）。

Ben-Hur and Noble (2005)结合pairwise kernels，无权重相加。

### Heuristic Approaches


# Experiment

数据集：four dataset
核函数：linear kernel, gaussian kernel

## Compared algorithms

RBMKL
ABMKL
CABMKL
MKL
SimpleMKL
GMKL
GLMKL
NLMKL
LMKL
-->

<h2 id="section-2">其他</h2>

<ul>
  <li>Quadratic Programming (QP，二次规划)：如果目标函数为凸二次函数，这个优化问题成为二次优化问题：<img src="file:///Users/wangruchen/work/learningMaterials/MachineLearning/MultipleKernelLearning/figure/QP.png" alt="QP" /></li>
  <li>(SOCP，二次锥规划问题)</li>
  <li>Quadratically Constrained Quadratic Programming (QCQP，二次约束的二次规划)：如果目标函数和约束项是凸二次函数，称这个凸优化问题为二次约束二次规划问题：<img src="file:///Users/wangruchen/work/learningMaterials/MachineLearning/MultipleKernelLearning/figure/QCQP.png" alt="QCQP" /></li>
  <li>Semidefinite Programming (SDP，半正定规划)：<img src="file:///Users/wangruchen/work/learningMaterials/MachineLearning/MultipleKernelLearning/figure/SDP.png" alt="SDP" /></li>
  <li>Semi-infinite Linear Program (SILP，半无限线性规划)：一个优化问题，有有限的变量和无限的约束条件，或者有无限的变量和有限的约束条件。</li>
</ul>

<h2 id="section-3">总结</h2>

<p>多核学习根据核函数结合方法的不同可以分为：</p>

<ol>
  <li>无权重参数：fixed rules（按照特定的形式结合），Boosting approaches（像集成学习类似）</li>
  <li>有权重参数：Heuristic approaches，Optimization approaches（通过解优化问题得到参数），Bayesian approaches</li>
</ol>

<p>得到结合参数时解的优化问题可以分为：</p>

<ol>
  <li>Similarity-based functions</li>
  <li>Structural risk functions</li>
  <li>Bayesian functions</li>
</ol>

<p>按核函数的结合方式可以分为：</p>

<ol>
  <li>Linear combination（相加或求平均等）</li>
  <li>Nonlinear combination（相乘或取幂等）</li>
  <li>Data-dependent combination</li>
</ol>

<p>训练过程有无迭代：</p>

<ol>
  <li>One-step methods</li>
  <li>Two-step methods</li>
</ol>

<p>基本学习方法：</p>

<ol>
  <li>SVM SVR</li>
  <li>KFDA (Kernel Fisher discriminant analysis)</li>
  <li>RKDA (Regularized kernel discrimi- nant analysis)</li>
  <li>KRR (Kernel ridge regression)</li>
</ol>





    <section class="footer ">

    <div class="row">

        <div class="col-sm-offset-3 col-md-offset-3 col-md-6 text-center">
            
      <span>
        <a class="header-link" href="https://github.com/wangruchen" target="_blank">
            <i class="fa fa-2x fa-github-square 3x"></i>
        </a>
      </span>
            


            

            


            
        </div>

    </div>
  <div class="row">
  <div class="col-sm-offset-2 col-sm-5 col-md-offset-5 col-md-6 ">
    <small><a href="http://www.mahabubislam.com">Mahabub I. </a><sup>&reg </sup>--- powerd by <a href="http://jekyllrb.com/">Jekyll</a></small>
  </div>

 
      <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'prioblog'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
    </script>


</section>


    </div>
    <!-- Scripts -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="assets/js/jquery.js"><\/script>')</script>

<!-- Add custom scripts here -->
<!-- Bootstrap js -->
<script type="text/javascript" src="js/bootstrap.min.js"></script>

<!-- Parallax js -->
<script type="text/javascript" src="jquery.localscroll-1.2.7-min.js"></script>
<script type="text/javascript" src="jquery.parallax-1.1.3.js"></script>
<script type="text/javascript" src="jquery.scrollTo-1.4.2-min.js"></script>
<script src="js/snippet.js"></script>
<!-- /end of parallax js -->



<!-- Add your google analytics here -->
<!-- Change the XXXXXXX section in your site id -->
<script>
    (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
            function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
        e=o.createElement(i);r=o.getElementsByTagName(i)[0];
        e.src='//www.google-analytics.com/analytics.js';
        r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
    ga('create','UA-XXXXX-X');ga('send','pageview');
</script>

	


  </body>

</html>
